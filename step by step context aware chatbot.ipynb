{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Context aware chatbot.**\n",
        "\n",
        "Chat bot for informative answers based on the conversation history and retrieved documents. It utilizes ChatOpenAI from the langchain_openai library and implements a retrieval system using FAISS. In this case, the relevant document is a JSON file.\n",
        "Using ChatPromptTemplate, the code generates responses based on retrieved documents, conversation history, and the user's input.\n",
        "\n",
        "\n",
        "References:\n",
        "\n",
        "https://github.com/BelgiAmir/TenMinutesChatbot/blob/main/LangChain%20Demo.ipynb\n",
        "\n",
        "https://streamlit.io/\n",
        "\n",
        "https://www.langchain.com/\n",
        "\n",
        "https://medium.com/@ahmed.mohiuddin.architecture/using-ai-to-chat-with-your-documents-leveraging-langchain-faiss-and-openai-3281acfcc4e9"
      ],
      "metadata": {
        "id": "MMyy5KpOpeLP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installation & Imports**"
      ],
      "metadata": {
        "id": "GzpRx7POvX0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install langchain\n",
        "%pip install langchain-openai\n",
        "%pip install jq\n",
        "%pip install faiss-cpu\n",
        "%pip install streamlit"
      ],
      "metadata": {
        "id": "w4EMrI2gNKM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg1sH1TAoEYs"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.document_loaders import JSONLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import create_history_aware_retriever\n",
        "from langchain_core.prompts import MessagesPlaceholder\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Build the app**\n"
      ],
      "metadata": {
        "id": "aIut4k8iwJld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Title and side bar"
      ],
      "metadata": {
        "id": "o75Ak5fMxseE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "st.title(\"ðŸ’¬ Laboratory company Chatbot\"\")\n",
        "st.caption(\"Chatbot that answers questions about UV detector catalog\")\n",
        "\n",
        "# Sidebar for API key input\n",
        "with st.sidebar:\n",
        "    OPENAI_API_KEY = st.text_input(\"OpenAI API Key\", key=\"chatbot_api_key\", type=\"password\")\n",
        "    \"[Get an OpenAI API key](https://platform.openai.com/account/api-keys)\"\n",
        "    \"[View the source code](https://github.com/franconti/context_aware_chatbot)\"\n",
        "\n",
        "# Check for API key\n",
        "if not OPENAI_API_KEY:\n",
        "    st.info(\"Please add your OpenAI API key to continue.\")\n",
        "    st.stop()"
      ],
      "metadata": {
        "id": "0IgZpMwTx_Zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the llm API wrapper"
      ],
      "metadata": {
        "id": "ID8MU5vWz52k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(openai_api_key= OPENAI_API_KEY, model_name=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "C5qkaAJw0Bgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing Chatbot With Memory"
      ],
      "metadata": {
        "id": "EwsF8n1w0Cii"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and process the data\n",
        "loader = JSONLoader(\n",
        "    file_path='UVdetectors.json',\n",
        "    jq_schema='.UVDetectors.models[]',\n",
        "    text_content=False)\n",
        "docs = loader.load()\n",
        "\n",
        "# Split the data\n",
        "text_splitter = RecursiveCharacterTextSplitter()\n",
        "documents = text_splitter.split_documents(docs)\n",
        "\n",
        "# Embedd the data (to convert text into numerical vector representations)\n",
        "embeddings = OpenAIEmbeddings(openai_api_key= OPENAI_API_KEY)\n",
        "vector = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "# Create retriever to query the vector database\n",
        "retriever = vector.as_retriever()"
      ],
      "metadata": {
        "id": "wDp_sPYU0RrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the retrival chain - Giving the chain ability to rereive data"
      ],
      "metadata": {
        "id": "Orj_1FzN54kT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the retrieval chain\n",
        "\"\"\"Combines the language model (llm), the retriever (which is a FAISS vector), and the prompt template to\n",
        " create a chain that is capable of generating search queries based on the conversation history and retrieving relevant documents.\"\"\"\n",
        "\n",
        "retrieval_chain_prompt = ChatPromptTemplate.from_messages([\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
        "])\n",
        "retriever_chain = create_history_aware_retriever(llm, retriever, retrieval_chain_prompt)"
      ],
      "metadata": {
        "id": "tBHwiWSe8gua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the documents chain - Answering the user input"
      ],
      "metadata": {
        "id": "qKQmIE239DsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the document chain that guides the chatbot on how to interact with users.\n",
        "document_chain_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"This is a chatbot for BiologyArte, a laboratory supplies company.\\\n",
        "      The chatbot's goal is to provide information and assistance to potential and existing BiologyArte customers.. \\\n",
        "      The chatbot should decline to answer any question not related to the company goal. \\\n",
        "      The chatbot should be friendly, polite, and helpful. \\\n",
        "      The chatbot should refer the user to the official website or a human representative if it cannot answer the question or handle the request. \\\n",
        "      Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
        "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "document_chain = create_stuff_documents_chain(llm, document_chain_prompt)"
      ],
      "metadata": {
        "id": "b5IixHii9NlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combining both chains"
      ],
      "metadata": {
        "id": "twqbDErdBHHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_chain = create_retrieval_chain(retriever_chain, document_chain)"
      ],
      "metadata": {
        "id": "WmG73rh6BKSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize chat history"
      ],
      "metadata": {
        "id": "i2XaOEE6BcOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if \"messages\" not in st.session_state:\n",
        "    st.session_state[\"messages\"] = [{\"role\": \"assistant\", \"content\": \"How can I help you?\"}]\n"
      ],
      "metadata": {
        "id": "l1D6DcVDB5SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Display chat messages"
      ],
      "metadata": {
        "id": "gp7W70QcB20u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for msg in st.session_state.messages:\n",
        "    st.chat_message(msg[\"role\"]).write(msg[\"content\"])"
      ],
      "metadata": {
        "id": "TvAFWYPEB9hF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handle user input"
      ],
      "metadata": {
        "id": "DjCLDAUSCB-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if prompt := st.chat_input():\n",
        "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "    st.chat_message(\"user\").write(prompt)\n",
        "    response = combined_chain.invoke({\"input\": prompt, \"chat_history\": st.session_state.messages})\n",
        "    msg = response[\"answer\"]\n",
        "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": msg})\n",
        "    st.chat_message(\"assistant\").write(msg)\n"
      ],
      "metadata": {
        "id": "Ii9l0gP5wbBl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
